\documentclass[a4paper,12pt]{report}
% see pages 625 for the explanation of packages below

\usepackage{ragged2e} %set the allign of a paragraph
\usepackage{lipsum}% http://ctan.org/pkg/lipsum
\usepackage[dotinlabels]{titletoc}% http://ctan.org/pkg/titletoc
\usepackage{tocloft}
\usepackage{wrapfig}
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usepackage[section]{placeins}
\usepackage{lscape}
\usepackage{amssymb}

\usepackage[top=3cm,bottom=3cm,left=3.77cm,right=3cm]{geometry}
%\usepackage{tikz}
%\usepackage{filecontents}
%\usepackage[nottoc,notlot,notlof]{tocbibind}
\usepackage{afterpage}
\usepackage{amsmath}
%\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage[framed,autolinebreaks]{mcode}
\usepackage{sectsty}
\usepackage{textcomp}
\usepackage{indentfirst}%the beginning of chapter/section is intended by usual paragraph indentetion
\usepackage[font=footnotesize]{caption}
% paket yg ditambahin sendiri
\usepackage{booktabs}


\linespread{2}
\setlength{\parindent}{4em}
\everymath{\displaystyle}


\titleformat{\chapter}[display]{\center\normalfont\large\bfseries}{\MakeUppercase{\chaptertitlename}\ \thechapter}{0pt}{\MakeUppercase}
\titlespacing*{\chapter}{0pt}{0pt}{30pt}
\sectionfont{\large}

\renewcommand{\cfttoctitlefont}{\large\bfseries}
%==================================================================
\addtocontents{toc}{\protect\flushleft\protect\afterpage{}}

\titlecontents{chapter}
[0pt]
{\vspace{1.5em}\small\bfseries}%
{\contentsmargin{0pt}%
\makebox[0em][l]{BAB \thecontentslabel\enspace}%
\hspace{5em}}
{}
{\titlerule*[0.5pc]{.}\contentspage}


\titlecontents{section}
  [5.5em]{}{\thecontentslabel\hspace{1em}}{}{\titlerule*[0.5pc]{.}\contentspage}
  
\titlecontents{subsection}
  [7.7em]{}{\thecontentslabel\hspace{1em}}{}{\titlerule*[0.5pc]{.}\contentspage}

  
%=============================================================
%set panjang dan lebar untuk .tikz
%\newlength\
\newlength\figurewidth

\lstset{
	language=Python,
	lineskip=1.5pt,
	breaklines=true
}


%================tulisan dengan font Helvetica================
\newenvironment{myfont}{\fontfamily{pcr}\selectfont}{\par}
\DeclareTextFontCommand{\textmyfont}{\myfont}
%=============================================================
\usepackage{float}
\usepackage{longtable}
\usepackage{setspace}
\usepackage{pgfplots}
%\pgfplotsset{compat=1.15}
\usepackage{mathrsfs}
\usetikzlibrary{arrows}
%======================
\newlength{\mylenj}

\renewcommand{\cftfigpresnum}{\figurename\enspace}
\renewcommand{\cfttabpresnum}{\tablename\enspace}
\settowidth{\mylenj}{\cftfigpresnum\cftfigaftersnum}
\addtolength{\cftfignumwidth}{5em}
\addtolength{\cfttabnumwidth}{5em}

\begin{document}
%============================================================

\renewcommand{\chaptername}{\large BAB}
\renewcommand{\figurename}{Gambar}
\renewcommand{\tablename}{Tabel}
\renewcommand{\contentsname}{\vskip -2cm\centerline{DAFTAR ISI}}
\renewcommand{\bibname}{DAFTAR PUSTAKA} 
\renewcommand{\listfigurename}{\vskip -1.9cm \centerline{\large{DAFTAR GAMBAR}}}
\renewcommand{\listtablename}{\vskip -2.2cm \centerline{\large{DAFTAR TABEL}}}
\newcommand{\listappendicesname}{\vskip -1.8cm \centerline{\large{DAFTAR LAMPIRAN}}}
\renewcommand*{\proofname}{\textbf{\emph{Bukti.}}}
\renewcommand{\qedsymbol}{$\blacksquare$}
%
\newtheorem{theorem}{Teorema}
\newtheorem{lemma}{Lema}
\newtheorem{proposition}{Proposisi}
\newtheorem{fact}{Fakta}
\newtheorem{definition}{Definisi}
\newtheorem{corollary}{Akibat}
\theoremstyle{definition}
\newtheorem{example}{Contoh}
%
\renewcommand{\thefigure}{\arabic{chapter}.\arabic{section}.\arabic{figure}}
\renewcommand{\thetable}{\arabic{chapter}.\arabic{section}.\arabic{table}}
\renewcommand{\thechapter}{\Roman{chapter}}
\renewcommand{\thesection}{\arabic{chapter}.\arabic{section}}
\renewcommand{\thesubsection}{\arabic{chapter}.\arabic{section}.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\arabic{chapter}.\arabic{section}.\arabic{subsection}.\arabic{subsubsection}}
\numberwithin{equation}{section}
\numberwithin{definition}{section}
\numberwithin{theorem}{section}
\numberwithin{corollary}{section}
\numberwithin{lemma}{section}
\numberwithin{example}{section}
\numberwithin{proposition}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}
%===========================================
\newlistof{appendices}{apc}{\listappendicesname}
\newcommand{\appendices}[1]{\addcontentsline{apc}{appendices}{#1}}

\newcommand{\newappendix}[1]{\section*{#1}\appendices{#1}}

%\tolerance=1
%\emergencystretch=\maxdimen
%\hyphenpenalty=10000
%\hbadness=10000
%\newcommand\scalemath[2]{\scalebox{#1}{\mbox{\ensuremath{\displaystyle}}}}
%===========================================
%Pendefinisian Untuk Lembar Pengesahan
\newcommand{\TTD}[4][5cm]{%
  \begin{tabular}{@{}p{#1}@{}}
    #2 \\[2em]
    \underline{#3} \\
    [-1.1em]
    {\small{NIP. #4}}
  \end{tabular}
}

\newcommand{\TTDKajur}[2]{%
   \begin{center}
     \begin{tabular}{c c c}
    Mengetahui, \\[-1em]
    Ketua Departemen\\[2.5em]
    \underline{#1} \\
    [-1.1em]
    {\small{NIP. #2}}
  	 \end{tabular}
   \end{center}
}

\newcommand{\TTDKosong}[4][5cm]{%
  \begin{tabular}{@{}p{#1}@{}}
  \end{tabular}
}

%=========={mulai mengetik dari sini}===========================
\begin{titlepage}
	\begin{center}
	\renewcommand{\baselinestretch}{2.0}\normalsize
	{\large \textbf{\textbf{PENERAPAN MODEL \textit{DEEP NEURAL NETWORK} PADA SISTEM DETEKSI INTRUSI JARINGAN}}}\\
	\vfill
	{\large \textbf{SKRIPSI}}\\[1ex]
	{\large \textbf{PROGRAM STUDI S1 MATEMATIKA}}
	\vfill
	\textbf{OLEH}\\
	\textbf{{FIKRI MULYANA SETIAWAN}}\\
	\textbf{NIM 2110432032}
	\vfill
	\includegraphics[scale=0.13]{UNANDLOGO.PNG}
	\vfill
	{\textbf{DEPARTEMEN MATEMATIKA DAN SAINS DATA}}\\
	\textbf{FAKULTAS MATEMATIKA DAN ILMU PENGETAHUAN ALAM}\\
	\textbf{UNIVERSITAS ANDALAS}\\
	\textbf{PADANG}\\
	\textbf{2025}
	\end{center} 
\end{titlepage}
%==============================================================
\pagenumbering{roman}
\thispagestyle{empty}
%
\newpage
\addcontentsline{toc}{chapter}{DAFTAR ISI}
\tableofcontents
\newpage
%========================================================
%DAFTAR GAMBAR JIKA PERLU
\newpage
\renewcommand{\baselinestretch}{2.0}\normalsize
\addcontentsline{toc}{chapter}{DAFTAR GAMBAR} 
\listoffigures
%========================================================
%DAFTAR TABEL JIKA PERLU
\newpage
\renewcommand{\baselinestretch}{2.0}\normalsize
\addcontentsline{toc}{chapter}{DAFTAR TABEL}
\listoftables
%==============================================================
%==============================================================
%DAFTAR LAMPIRAN JIKA PERLU
\newpage
\renewcommand{\baselinestretch}{2.0}\normalsize
\addcontentsline{toc}{chapter}{DAFTAR LAMPIRAN}
{\listofappendices}

%==============================================================
% untuk ngatur penggalan kata
\tolerance=1
\emergencystretch=\maxdimen
\hyphenpenalty=10000
\hbadness=10000


\chapter{PENDAHULUAN}

\pagenumbering{arabic}
\thispagestyle{empty}

\section{Latar Belakang}

Pesatnya perkembangan teknologi informasi telah memudahkan manusia di banyak sektor penting kehidupan. Pada sektor ekonomi, perkembangan teknologi informasi telah memudahkan manusia dalam perdagangan secara global. Pada sektor pendidikan dan pemerintahan, teknologi informasi telah memudahkan peneliti untuk berkolaborasi serta memudahkan pemerintah untuk menyebarkan informasi secara luas kepada masyarakat. Penggunaan teknologi informasi secara masif ini menghasilkan peningkatan ukuran jaringan dan jumlah data yang mengalir di jaringan dengan pesat \cite{ahmadNetworkIntrusionDetection2021}, seperti data transaksi keuangan, data informasi pribadi dan data penting lainnya. Akan tetapi, seiring perkembangan teknologi informasi, ancaman yang menyertainya juga turut berkembang. 

Menurut \textit{National Institute of Standard and Technology} (NIST), intrusi merupakan kejadian, atau rangkaian kejadian dimana seseorang mendapatkan atau mencoba mendapatkan akses ke sistem atau sumber daya sistem tanpa memiliki otoritas untuk melakukannya \cite{nationalinstituteofstandardstechnologyIntrusion}. Dengan kata lain, intrusi dapat diartikan sebagai percobaan yang dilakukan untuk mengakses sistem secara tidak sah dengan tujuan untuk merusak atau menyalahgunakannya. 

Pada dasarnya, hampir semua sistem jaringan yang ada mempunyai celah keamanan yang mengakibatkan sistem tersebut rentan terhadap intrusi dan penyalahgunaan oleh orang dalam \cite{luntSurveyIntrusionDetection1993}. Walaupun begitu, menemukan dan memperbaiki semua celah keamanan tersebut tidak mudah, dan di sisi lain mengembangkan sistem yang tidak memiliki celah keamanan sama sekali juga merupakan suatu hal yang hampir mustahil untuk dilakukan \cite{luntSurveyIntrusionDetection1993}\cite{denningIntrusionDetectionModel1987}. Oleh karena itu, diperlukan sebuah sistem yang mampu mendeteksi intrusi jaringan secara \textit{real-time} dan memberikan peringatan lebih awal (\textit{early warning}) sehingga pihak berwenang dapat mengatasinya sebelum serangan itu berkembang lebih lanjut. Sistem ini dikenal sebagai \textit{Intrusion Detection System} (IDS).

Sistem deteksi intrusi pertama kali diperkenalkan oleh Jim Anderson pada tahun 1980 \cite{andersonComputerSecurityThreat1980} yang menggunakan pendekatan statistik untuk mendeteksi intrusi. Jim Anderson menggunakan asumsi awal bahwa suatu aktivitas dapat dikategorikan ke jenis aktivitas tertentu (normal atau serangan) jika aktivitas tersebut memperlihatkan sifat yang sama dengan kelompok aktivitas terntu, yaitu kelompok aktivitas normal dan serangan. Sejak saat itu, berbagai penelitian telah dilakukan untuk pengembangan sistem deteksi intrusi yang lebih baik, efektif, dan efisien. 

Salah satu penelitian yang cukup populer yaitu penelitian yang dilakukan oleh \textit{Lincoln Laboratory of MIT} yang melakukan evaluasi terhadap sistem deteksi intrusi menggunakan metode \textit{Receiver Operating Characteristic} (ROC). Akan tetapi, penelitian ini mendapat cukup banyak kritikan, seperti yang dilakukan oleh John McHugh yang mengkritik metode evaluasi yang digunakan karena metode ROC sendiri memiliki beberapa asumsi dasar yang perlu terpenuhi \cite{mchugh1998LincolnLaboratory2000}, sedangkan pada penelitian tersebut tidak disebutkan secara jelas apakah asumsi tersebut terpenuhi. Tidak adanya informasi yang jelas mengenai terpenuhinya asumsi ini dapat memberikan hasil evaluasi yang bias \cite{mchugh1998LincolnLaboratory2000}. 

Tak berselang lama setelah penelitian yang dilakukan oleh \textit{Lincoln Laboratory of MIT}, Pada tahun 2001 Dickerson melakukan penelitian mengenai pengembangan sistem deteksi intrusi jaringan menggunakan pendekatan \textit{fuzzy logic} \cite{dickersonFuzzyIntrusionDetection2001}. Pada penelitian ini, metode \textit{Fuzzy C-Means Clustering} digunakan untuk mendeteksi intrusi. Metode ini bekerja cukup baik walaupun dengan \textit{false negative rate}, yaitu proporsi hasil negatif yang salah diprediksi oleh model, yang bernilai cukup tinggi.

Pada tahun 2019, Xianwei Gao mengembangkan sistem deteksi intrusi dengan pendekatan \textit{machine learning}. Xianwei menggunakan metode \textit{ensemble} adaptif dengan beberapa \textit{classifier}, seperti \textit{Decision Tree}, \textit{Deep Neural Network}, \textit{K-Nearest Neighbor} (KNN), dan beberapa \textit{classifier} lain \cite{gaoAdaptiveEnsembleMachine2019} dengan dataset pelatihan yang bernama NSL-KDD. Dengan menggunakan pendekatan ini, metode \textit{ensemble} adaptif yang dikembangkan berhasil memperoleh akurasi 85,2\%.

Disamping pendekatan \textit{machine learning} klasik, metode deteksi intrusi jaringan dengan model berbasis \textit{deep learning} juga menunjukkan hasil yang cukup menjanjikan. Pada tahun 2017, Chuanlong Yin menggunakan pendekatan \textit{deep learning} dengan model \textit{Recurrent Neural Network} (RNN) untuk melakukan deteksi intrusi \cite{yinDeepLearningApproach2017}. Berdasarkan hasil yang diperoleh, diketahui bahwa model RNN yang dikonstruksi menunjukkan performa yang lebih baik dibandingkan model \textit{machine learning} tradisional seperti \textit{random forest} dan \textit{naive bayes classifier} \cite{yinDeepLearningApproach2017}. Model RNN menawarkan akurasi yang tinggi dengan \textit{false positive rate} yang rendah. 

Pada tahun 2020, Wooyeon dkk. menggunakan model \textit{Convolutional Neural Network} (CNN) mendeteksi intrusi. \cite{joPacketPreprocessingCNNBased2020}. Pada penelitiannya, Wooyeon dkk. diajukan 3 teknik \textit{preprocessing} data, yaitu \textit{direct conversion}, \textit{weighted conversion} dan \textit{compressed conversion} \cite{joPacketPreprocessingCNNBased2020}. Ketiga teknik \textit{preprocessing} ini digunakan untuk mengonversi data pada dataset NSL-KDD menjadi data gambar untuk diolah menggunakan model \textit{Convolutional Neural Network} (CNN). Dengan menggunakan teknik ini, model CNN berhasil mencapai akurasi sebesar 88,2\%. Penelitian ini menunjukkan keunggulan model berbasis \textit{deep learning} untuk masalah deteksi intrusi.

Berdasarkan penelitian mengenai sistem deteksi intrusi yang telah dilakukan sebelumnya, diketahui model berbasis \textit{neural network} banyak diterapkan untuk masalah deteksi intrusi jaringan dan bahkan memiliki performa yang lebih baik dibandingkan dengan model \textit{machine learning} klasik. Oleh karena itu, pada penelitian ini Penulis akan mengkaji penerapan model \textit{deep learning} \textit{Deep Neural Network} (DNN) untuk sistem deteksi intrusi jaringan. Pada penelitian ini, model DNN akan digunakan untuk melakukan klasifikasi data dengan kelas biner (BENIGN dan ATTACK) sehingga dapat digunakan untuk deteksi intrusi. 

\section{Rumusan Masalah}

Berdasarkan latar belakang di atas, masalah yang dibahas pada penelitian ini adalah:
\begin{enumerate}
	\item Bagaimana arsitektur dan \textit{hyperparameter} dari model deteksi intrusi berbasis \textit{Deep Neural Network} (DNN)?
	\item Bagaimana performa dari model deteksi intrusi berbasis \textit{Deep Neural Network} (DNN) berdasarkan metrik evaluasi \textit{accuracy}, \textit{precision}, dan \textit{recall}?
\end{enumerate}

\section{Tujuan Penelitian}

Berdasarkan rumusan masalah yang telah dipaparkan, penelitian ini memiliki tujuan yang ingin dicapai, yaitu:
\begin{enumerate}
	\item Memperoleh arsitektur dan  \textit{hyperparameter} model deteksi intrusi berbasis \textit{Deep Neural Network} (DNN).
	\item Mengetahui seberapa baik model berbasis \textit{Deep Neural Network} (DNN) dalam melakukan deteksi intrusi berdasarkan metrik evaluasi \textit{accuracy}, \textit{precision}, dan \textit{recall}.
\end{enumerate} 

\section{Sistematika Penulisan}

Skripsi ini terdiri dari lima bab. Pada Bab I, dimuat latar belakang, perumusan masalah, tujuan penulisan dan sistematika penulisan. Kemudian pada Bab II dibahas tentang konsep dasar yang menjadi landasan untuk penelitian ini. Bab III berisi informasi sumber data yang digunakan, dan tahapan yang dilakukan dalam penelitian. Pada Bab IV, terdapat pembahasan mengenai implementasi \textit{Deep Neural Network} (DNN) untuk sistem deteksi intrusi, serta evaluasi dari hasil deteksi model yang diperoleh. Terakhir untuk Bab V memuat kesimpulan dari penelitian yang telah dilaksanakan dan saran untuk penelitian berikutnya.

%==============================================================
\chapter{LANDASAN TEORI}
\thispagestyle{empty}

\section{Sistem Komunikasi Jaringan Komputer}
Jaringan komputer merupakan kumpulan komputer (\textit{node}) yang dihubungkan melalui saluran transmisi tertentu yang memungkinkan komputer untuk berkomunikasi dan berbagi informasi \cite{robertazziIntroductionComputerNetworking2017}. Agar komputer yang terkoneksi di dalam jaringan dapat berkomunikasi dengan baik, terdapat aturan yang meregulasi format data yang dikirimkan, mekanisme pengiriman data, dan tujuan pengiriman data. Aturan ini disebut sebagai protokol \cite{tanenbaumComputerNetworks2011}. Terdapat beberapa protokol yang digunakan untuk fungsi yang berbeda-beda, seperti \textit{Transmission Control Protocol} (TCP) dan \textit{User Datagram Format} (UDP). 

Pada saat komputer berkomunikasi melalui jaringan, data ditransmisikan dalam bentuk pecahan data yang lebih kecil yang disebut sebagai \textit{packets}, dan masing-masing \textit{packets} ditransmisikan melalui rute yang berbeda-beda untuk efisiensi transmisi \cite{tanenbaumComputerNetworks2011}\cite{robertazziIntroductionComputerNetworking2017}. Mekanisme ini dikenal dengan nama \textit{packets switching}. Pengiriman \textit{packets} dengan mekanisme seperti ini mengakibatkan \textit{packets} tidak langsung terkirim dari pengirim ke penerima, melainkan melalui \textit{node} lain yang terhubung ke jaringan yang sama terlebih dahulu, seperti pada Gambar \ref{packets_switching}.

\begin{figure}[H]
	\center \includegraphics[width=\linewidth]{assets/packets_switching}
	\caption{Ilustrasi Mekanisme Pengiriman Data dengan \textit{Packets Switching}} 
	\label{packets_switching}
\end{figure}

Sebagai contoh, data yang dikirimkan dari Melbourne (Australia) dengan penerima di Padang mungkin tidak dapat terjadi secara langsung, melainkan melalui beberapa node lain pada jaringan terlebih dahulu, misalnya melalui Jakarta dan kemudian baru diteruskan ke Padang. Data yang dipecah menjadi sejumlah \textit{packets} dapat melewati rute yang berbeda-beda walaupun memiliki tujuan yang sama. Penentuan rute transmisi \textit{packets} yang dikirimkan ini disebut sebagai \textit{routing} \cite{tanenbaumComputerNetworks2011}.

\section{Intrusi}

Intrusi merupakan kejadian dimana seseoarang mendapatkan akses atau berusaha mendapatkan akses ke sebuah sistem tanpa memiliki otoritas untuk melakukannya. Upaya yang dilakukan untuk mendapatkan akses ini disebut sebagai serangan. Beberapa jenis serangan yang cukup populer untuk melakukan intrusi yaitu:
\begin{enumerate}
	\item \textit{Denial of Services} (DOS). Serangan ini dilakukan dengan cara membanjiri jaringan dengan lalu lintas yang sangat tinggi dalam waktu yang relatif singkat \cite{hnamteDDoSAttackDetection2024}.
	
	\item \textit{Port Scan}. Salah satu langkah awal yang dilakukan untuk menyerang sebuah jaringan teknologi komunikasi adalah \textit{reconnaissance} (pengintaian). Langkah ini dilakukan untuk mengumpulkan informasi mengenai jaringan yang akan diserang dan menemukan celah \cite{hartpenceCombatingTCPPort2020}.
	
	\item \textit{Brute Force}. \textit{Brute force} bekerja dengan cara menebak kredensial login (\textit{username} dan \textit{password}) menggunakan berbagai kombinasi yang mungkin untuk mendapatkan akses pengguna tertentu \cite{groverEfficientBruteForce2020}. 
	
	\item \textit{Bot} dan \textit{Botnet}. \textit{Bot} merupakan program yang dikontrol jarak jauh untuk menyerang jaringan teknologi komunikasi. \textit{Botnet} merupakan sekumpulan bot yang dikontrol oleh seorang penyerang yang disebut sebagai \textit{botmaster} dengan tujuan untuk mengirimkan \textit{spam} dan mencuri data \cite{qureshiBotnetAttacksCharacteristics2023}.
	
	\item \textit{Cross-Site Scripting} (XSS). XSS merupakan jenis serangan dimana penyerang akan menyisipkan skrip/kode berbahaya pada website di sisi \textit{client} \cite{weamieCrossSiteScriptingAttacks2022}.
	
	\item SQL \textit{Injection}. SQL \textit{Injection} merupakan jenis serangan yang menyerang data yang tersimpan pada database sebuah aplikasi dengan cara menyisipkan perintah SQL tertentu sehingga merusak fungsionalitas sistem dan memungkinkan penyerang mendapatkan akses yang tidak sah \cite{paulSQLInjectionAttack2024}\cite{owaspSQLInjection}.
	
	\item \textit{Heartbleed}. \textit{Heartbleed} merupakan sebuah celah/kerentanan (\textit{vulnerability}) yang ada pada koneksi \textit{open Secure Shell} (open SSL), yaitu perangkat lunak yang memungkinkan aplikasi di dalam sistem dapat berkomunikasi secara aman. Celah inilah yang kemudian digunakan oleh penyerang untuk menyerang sistem jaringan komunikasi.
\end{enumerate}

\section{Sistem Deteksi Intrusi}

Sistem deteksi intrusi atau \textit{Intrusion Detection System} (IDS) merupakan sebuah perangkat atau aplikasi yang dirancang untuk memantau lalu lintas jaringan dan mendeteksi aktivitas mencurigakan dan berpontensi menimbulkan pelanggaran hukum \cite{solomonIntrusionDetectionSystem2019}. Secara prinsip, sistem deteksi intrusi mampu memantau lalu lintas jaringan dan mendeteksi aktivitas mencurigakan secara \textit{real-time} sehingga mampu memberikan peringatan lebih awal (\textit{early warning}) kepada pihak berwenang untuk ditangani sesegera mungkin. 

Terdapat beberapa pendekatan yang pernah dilakukan untuk pengembangan sistem deteksi intrusi, mulai dari pendekatan \textit{fuzzy logic} yang dilakukan oleh Dickerson pada tahun 2001 \cite{dickersonFuzzyIntrusionDetection2001}. Penelitian mengenai pengembangan sistem deteksi intrusi pada tahun-tahun berikutnya cukup progresif, dengan adanya pendekatan \textit{machine learning} klasik, hingga pendekatan \textit{deep learning} yang menawarkan akurasi tinggi dan \textit{false negative rate} yang rendah. Tren penelitian mengenai sistem deteksi intrusi pada beberapa tahun kebelakang menunjukkan kecendrungan penggunaan model \textit{deep learning} untuk sistem deteksi intrusi yang andal.

\section{Neural Network}

 \textit{Neural network/artifical neural network} merupakan salah satu jenis model dalam \textit{machine learning} yang menjadi landasan utama untuk berbagai jenis teknologi berbasis kecerdasan buatan. \textit{Neural network} pertama kali muncul pada awal tahun 1940 dengan kemampuan untuk memodelkan data menggunakan fungsi nonlinier \cite{qamarArtificialNeuralNetworks2023}. Pada masa tersebut, pengembangan model \textit{neural network} didasari oleh 2 tujuan utama, yaitu untuk memahami bagaimana sistem saraf manusia bekerja dan mengembangkan sebuah sistem yang terinspirasi oleh jaringan saraf biologis sehingga dapat dimanfaatkan untuk mengembangkan sistem kecerdasan buatan. Hal ini dilakukan karena, meskipun komputer dapat melakukan proses komputasi lebih cepat dibandingkan otak manusia, komputer tidak bisa menyamai kemampuan kognitif otak manusia \cite{prietoNeuralNetworksOverview2016}.

Pembeda antara \textit{neural network} dengan model \textit{machine learning} lainnya adalah struktur dari modelnya yang terdiri dari \textit{input layer}, \textit{hidden layer}, dan \textit{output layer}. Setiap layer pada model \textit{neural network} terdiri dari \textit{node}, yaitu \textit{unit} komputasi yang merepresentasikan nilai yang disimpan pada tiap layer serta bobot (\textit{weight}) $w_{i,j}^{(l)}$ yang menghubungkan \textit{node} pada \textit{layer} ke-$l-1$ dengan \textit{node} pada layer ke-$l$. Proses komputasi pada model \textit{neural network} dilakukan di sejumlah \textit{node} (neuron) pada \textit{hidden layer} dan \textit{output layer} \cite{sohilIntroductionStatisticalLearning2022}\cite{qamarArtificialNeuralNetworks2023}. Nilai yang disimpan pada tiap \textit{node} dikenal sebagai nilai aktivasi, dan dihitung menggunakan sebuah fungsi yang dikenal sebagai fungsi aktivasi. 
\begin{enumerate}
	\item \textit{Input layer} merupakan \textit{layer} yang terdiri dari beberapa \textit{node} yang merepresentasikan fitur pada data. Vektor $X = (X_{1}, X_{2}, ..., X_{p})$ digunakan untuk membentuk \textit{input layer} dan direpresentasikan oleh \textit{node} sebanyak \textit{p}. 
	\item \textit{Hidden layer} berada di antara \textit{input layer} dan \textit{output layer}. \textit{Hidden layer} merupakan tempat dimana data input diproses sesuai dengan bobot dan fungsi aktivasi yang telah ditentukan.
	\item  \textit{Output layer} akan menerima hasil pemrosesan dari \textit{hidden layer} dan mentransformasinya menjadi nilai output.
\end{enumerate}

Gambar \ref{NN1layer} mengilustasikan arsitektur model \textit{neural network} dengan 1 \textit{hidden layer} yang juga dikenal sebagai \textit{single layer neural network}. Pada Gambar \ref{NN1layer}, setiap \textit{unit} pada $X, A$ dan $f(X)$ disebut sebagai \textit{node}. Tanda panah pada gambar di atas menunjukkan bahwa setiap \textit{node} pada \textit{input layer} dihubungkan ke setiap \textit{node} pada \textit{hidden layer}. \textit{Layer} dengan koneksi antar \textit{node} seperti ini disebut sebagai \textit{dense layer}. Nilai pada neuron di \textit{hidden layer}, yaitu $A_{1}, A_{2}, ... A_{K}$ dikenal sebagai nilai aktivasi dan dihitung berdasarkan persamaan (\ref{nilaiA}).
\begin{equation}
	A_{k}= g\left(w_{k,0}^{(1)} + \sum\limits_{j=1}^{p}w_{k,j}X_{j}\right)
	\label{nilaiA}
\end{equation}
\noindent dimana: \\
\begin{tabular}{l c l}
	$w_{k,0}$ &:& bias model pada \textit{hidden layer}, \\
	$w_{k,j}$ &:& bobot yang menghubungkan node $X_j$ ke node $A_k$, \\
	$g(\cdot)$ &:& fungsi aktivasi.
\end{tabular} \\

Fungsi $g(\cdot)$ pada persamaan (\ref{nilaiA}) disebut sebagai fungsi aktivasi. $K$ buah nilai aktivasi ini diberikan ke \textit{output layer} untuk menghitung $f(X)$, yaitu hasil prediksi model, berdasarkan persamaan (\ref{rumusfx}).
\begin{equation}
	\begin{split}
		\hat{Y} &= f(X) \\
		&= g\left(\beta_{0} + \sum\limits_{k=1}^{K}\beta_{k}A_{k}\right) \\
		&= g\left(\beta_{0} + \sum\limits_{k=1}^{K}\beta_{k}g\left(w_{k,0}^{(1)} + \sum\limits_{j=1}^{p}w_{k,j}X_{j}\right)\right)
	\end{split}
	\label{rumusfx}
\end{equation}
\noindent dimana: \\
\begin{tabular}{l c l}
	$\hat{Y}$ &:& hasil prediksi model, \\
	$\beta_{0}$ &:& bias model pada \textit{output layer}, \\
	$\beta_{k}$ &:& bobot yang menghubungkan node $A_j$ ke node $f(X)$ pada \textit{output layer}, \\
	$g(\cdot)$ &:& fungsi aktivasi.
\end{tabular}

\begin{figure}[H]
	\center \includegraphics[width=340px]{assets/graf4}
	\caption{Struktur Model \textit{Neural Network} dengan 1 \textit{Hidden Layer}} 
	\label{NN1layer}
\end{figure}

Terdapat beragam fungsi aktivasi yang dapat diterapkan pada model \textit{neural network}. Pemilihan fungsi aktivasi yang akan digunakan perlu mempertimbangkan masalah apa yang akan dihadapi oleh model. Sebagai contoh, fungsi \textit{sigmoid} cenderung digunakan untuk masalah klasifikasi biner, sedangkan fungsi \textit{softmax} cenderung digunakan untuk klasifikasi multi-kelas. Tabel \ref{tabelfungsi} menunjukkan beberapa fungsi aktivasi yang umum digunakan.
\begin{longtable}{|l|c|c|c|}
	\caption{Beberapa Fungsi Aktivasi} \label{tabelfungsi}\\
	\hline
	\textbf{Nama Fungsi} & \textbf{Definisi} & \textbf{Domain} & \textbf{Range} \\ \hline
	% Baris untuk Sigmoid
	Sigmoid & $\sigma(x) = \frac{1}{1 + e^{-x}}$ & $\mathbb{R}$ & $(0, 1)$ \\
	\hline
	
	% Baris untuk ReLU
	ReLU (Rectified Linear Unit) & $g(x) = \max(0, x)$ & $\mathbb{R}$ & $[0, \infty)$ \\
	\hline
	
	% Baris untuk Softmax
	Softmax & $\sigma(\mathbf{x})_i = \frac{e^{x_i}}{\sum_{j=1}^{J} e^{x_j}}$ & $\mathbb{R}^J$ & $(0, 1)$ \\
	\hline
	
	% Baris untuk Linear
	Linear & $g(x) = x$ & $\mathbb{R}$ & $\mathbb{R}$ \\
	\hline
\end{longtable}
Pada fungsi aktivasi yang ditunjukkan oleh Tabel \ref{tabelfungsi}, domain fungsi merupakan domain dari data \textit{input} pada model, sedangkan \textit{range} fungsi aktivasi merupakan interval nilai hasil pemetaan oleh fungsi aktivasi.

\section{\textit{Deep Neural Network}}

Model \textit{neural network} modern dapat terdiri dari lebih dari 1 \textit{hidden layer}, dan bahkan masing-masing \textit{layer} terdiri dari banyak \textit{node}. Model \textit{neural network} dengan arsitektur seperti ini disebut sebagai \textit{Deep Neural Network} atau \textit{Multi-Layer Neural Network}. Dengan adanya sejumlah \textit{hidden layer}, proses komputasi model akan memberikan hasil prediksi yang lebih akurat\cite{sohilIntroductionStatisticalLearning2022}. 

Perhitungan nilai aktivasi masing-masing \textit{node} pada setiap \textit{layer} dilakukan sebagai berikut. Misalkan $A_k^{(1)}$ merepresentasikan nilai aktivasi pada \textit{node} ke-$k$ di \textit{layer} pertama. Jika terdapat $K_1$ \textit{node} pada \textit{layer} pertama, maka:
\begin{equation}
	\begin{split}
		A_k^{(1)} &= g\left(w_{k,0}^{(1)} + \sum\limits_{j=1}^{p}w_{k,j}^{(1)}X_{j}\right)
	\end{split}
	\label{multilayerA1}
\end{equation}

Untuk perhitungan pada \textit{layer} kedua, \textit{layer} pertama akan dianggap sebagai \textit{input layer}, kemudian dilakukan perhitungan yang serupa dengan persamaan (\ref{multilayerA1}). Misalkan pada \textit{layer} kedua terdapat $K_2$ neuron, maka perhitungan untuk masing-masing neuron ($A_l^{(2)}$) adalah sebagai berikut :
\begin{equation}
	\begin{split}
		A_l^{(2)} &= h_l^{(2)}(X) \\
		&= g\left(w_{l,0}^{(2)} + \sum\limits_{k=1}^{K_1}w_{l,k}^{(2)}A_{k}^{(1)}\right)
	\end{split}
	\label{multilayerA2}
\end{equation}

\noindent dengan: \\
\begin{tabular}{p{1cm} p{0.5cm} p{10cm}}
	$A_l^{(2)}$ &:& neuron ke-$l$ pada \textit{layer} ke-2, \\
	$g(\cdot)$ &:& fungsi aktivasi, \\
	$w_{l,0}^{(2)}$ &:& bias, \\
	$A_k^{(1)}$ &:& neuron ke-$k$ pada layer pertama, \\
	$w_{l,k}^{(2)}$ &:& bobot yang menghubungkan neuron ke-$k$ pada layer pertama dengan neuron ke-$l$ pada layer kedua.
\end{tabular}

\begin{figure}[H]
	\center \includegraphics[width=300px]{assets/graf3}
	\caption{Ilustrasi \textit{Multilayer Neural Network}} 
	\label{sumbar}
\end{figure} 
Jika arsitektur \textit{neural network} memiliki lebih dari 2 \textit{layer}, perhitungan masing-masing layer dilakukan dengan cara yang sama. Pada \textit{layer} ketiga, \textit{layer} kedua digunakan sebagai \textit{input layer}. Pada \textit{layer} keempat, \textit{layer} ketiga digunakan sebagai \textit{input layer}, begitu seterusnya. 

Oleh karena terdapat $p$ fitur pada variabel $X$ dan terdapat $K$ unit neuron pada setiap hidden layer $A_1$, maka terdapat sebanyak $K \times (p+1)$ bobot (\textit{weights}) $w_{kj}$ yang menghubungkan input layer $X$ ke hidden layer $A_1$. Bobot $w_{kj}$ dapat direpresentasikan sebagai matriks $\mathbf{W}_1$, dimana:

\begin{equation}
	\begin{split}
		\mathbf{W}_1 &=  
		\begin{bmatrix}
			w_{1, 1} & w_{1, 2} & w_{1, 3} & \dots & w_{1, p} & w_{1, 0} \\
			w_{2, 1} & w_{2, 2} & w_{2, 3} & \dots & w_{2, p} & w_{2, 0} \\
			w_{3, 1} & w_{3, 2} & w_{3, 3} & \dots & w_{3, p} & w_{3, 0} \\
			\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
			w_{K, 1} & w_{K, 2} & w_{K, 3} & \dots & w_{K, p} & w_{K, 0}\\
		\end{bmatrix} \\
	\end{split}
	\label{matriksW}
\end{equation}

\begin{equation}
	\begin{split}
		X &=  
		\begin{bmatrix}
			X_{1}  \\
			X_{2}  \\
			\vdots    \\ 
			X_{p}  \\
			1 \\
		\end{bmatrix} \\
	\end{split}
	\label{vektorXl}
\end{equation} \\


Dengan begitu, perhitungan nilai aktivasi pada masing-masing neuron pada \textit{hidden layer} $A_1$ dapat dilakukan sebagai berikut \cite{sohilIntroductionStatisticalLearning2022} :
\begin{equation}
	\begin{split}
		A^{(1)} &= g\left( \mathbf{W}_1X \right)  
	\end{split}
	\label{vektorAl}
\end{equation} 
\noindent dimana: \\
\begin{tabular}{p{1cm} p{0.5cm} p{10cm}}
	$A^{(2)}$ &:& vektor \textit{node} pada \textit{layer} ke-2 \\
	$g(\cdot)$ &:& fungsi aktivasi dengan pemetaan per elemen vektor  \\
\end{tabular} \\

\section{\textit{Loss Function}}
\textit{Loss function} merupakan fungsi yang merepresentasikan seberapa jauh selisih nilai yang dihasilkan model dengan nilai yang sebenarnya. Pada masalah klasifikasi biner (\textit{binary classification}), \textit{loss function} yang umum digunakan adalah \textit{log-loss function} atau lebih populer dengan nama \textit{binary cross-entropy} (BCE). \textit{Binary cross-entropy} mengukur seberapa jauh selisih kelas biner dengan probabilitas prediksi kelas yang diperoleh berdasarkan model. \cite{elharroussLossFunctionsDeep2025}. BCE dinyatakan dalam bentuk fungsi pada persamaan (\ref{bce}).
\begin{equation}
	\begin{split}
		L(y, \hat{y}) = - (y \log(\hat{y}) + (1 - y) \log(1 - \hat{y})) \\
	\end{split}
	\label{bce}
\end{equation}
dimana : \\
\begin{tabular}{p{1cm} p{0.5cm} p{10cm}}
	$y$ &:& kelas sebenarnya (0 atau 1), \\
	$\hat{y}$ &:& probabilitas kelas prediksi, dimana {$\hat{y} \in (0, 1)$}. \\
\end{tabular} \\

\section{Optimasi Model}
Model \textit{deep learning} melibatkan sejumlah bobot (termasuk bias) yang perlu ditentukan nilainya. Tujuan utama dari proses optimasi model adalah menentukan bobot model sehingga menghasilkan \textit{loss function} yang minimal. Jika \textit{loss function} dinyakan sebagai $L(y, \hat{y})$, maka proses optimasi model dilakukan dengan cara mengestimasi nilai bobot $w_{k,j}$ sehingga $\frac{\partial L}{\partial w_{k,j}} = 0$. 

\textit{Backpropagation} merupakan metode yang dikembangkan untuk menentukan nilai dari semua bobot ini. \textit{Backpropagation} mampu memperbarui parameter pada model \textit{deep learning} selama proses pelatihan melalui 2 fase penting, yaitu fase \textit{forward} dan fase \textit{backward} dengan mekanisme sebagai berikut \cite{montesinoslopezMultivariateStatisticalMachine2022}\cite{pajankarHandsonMachineLearning2022}: 
\begin{enumerate}
	\item Fase \textit{forward}. Pada fase ini, data input akan diteruskan ke \textit{hidden layer} untuk diproses menggunakan nilai bobot awal yang ditentukan. Berikutnya, hasil pemrosesan oleh \textit{hidden layer} akan digunakan untuk menghitung nilai \textit{output} pada \textit{output layer}. Setelah \textit{output} diperoleh, selanjutnya \textit{loss function} dari \textit{output} akan dihitung.
	\item Fase \textit{backward}. Setelah \textit{loss function} dihitung, turunan dari \textit{loss function} (\textit{gradient}) terhadap setiap bobot pada \textit{layer} akan dihitung dengan arah mundur (\textit{backward}), dimulai dari \textit{layer} yang paling dekat dengan \textit{output layer} \cite{aggarwalNeuralNetworksDeep2018}.  
\end{enumerate}

Pada arstiketur \textit{neural network} yang kompleks, proses pembaruan bobot ini melibatkan operasi yang menggunakan aturan rantai multi-variabel. Misalkan terdapat sejumlah neuron $h_1, h_2, ..., h_k$ dan 1 neuron output $o$ dimana $w_{h_r, h_{r+1}}$ adalah bobot yang menghubungkan neuron $h_r$ dengan neuron $h_{r+1}$. Kemudian, misalkan terdapat sejumlah lintasan dari \textit{node} $h_1$ ke \textit{node} $0$ yang dinyatakan dalam himpunan $\mathcal{P}$. Secara matematis, perhitungan gradien \textit{loss function} terhadap bobot $w_{h_r, h_{r+1}}$ dinyatakan pada persamaan (\ref{bpformula}).
\begin{equation}
	\begin{split}
		\frac{\partial L}{\partial w_{(h_{r-1},h_r)}} = \frac{\partial L}{\partial o} \cdot \left[ \sum_{[h_r, h_{r+1}, ..., h_{k}, o] \in \mathcal{P}} \frac{\partial o}{\partial h_k} \prod_{i=r}^{k-1} \frac{\partial h_{i+1}}{\partial h_i} \right] \frac{\partial h_r}{\partial w_{(h_{r-1},h_r)}} \quad \forall r \in 1...k \\
	\end{split}
	\label{bpformula}
\end{equation}

Terdapat beberapa metode untuk memperbarui bobot yang ada secara efektif, salah satu metode yang populer digunakan adalah \textit{Adaptive Moment Estimation} (ADAM). Tahapan pembaruan bobot (\textit{weights}) ini juga disebut sebagai pelatihan model (\textit{model training}).

\section{\textit{Gradient Descent}}
Hampir semua masalah pada \textit{machine learning} dapat dikonstruksi menjadi masalah optimasi terhadap suatu fungsi tertentu, yaitu \textit{loss function}. Tujuan utama dari pelatihan model \textit{machine learning} adalah menentukan parameter model yang meminimalkan \textit{loss function}. 

Pada metode berbasis \textit{gradient descent}, penentuan nilai parameter $W$ yang meminimalkan \textit{loss function} $L$ ini dilakukan dengan cara menggeser nilai parameter ke arah yang berlawanan dengan gradien dari \textit{loss function} \cite{aggarwalNeuralNetworksDeep2018}. Secara matematis, pembaruan parameter model menggunakan metode \textit{gradient descent} dilakukan berdasarkan persamaan (\ref{grad_descent}). nilai $\alpha$ pada persamaan (\ref{grad_descent}) disebut sebagai \textit{learning rate}, dan mengindikasikan seberapa jauh parameter digeser dari nilai awalnya.
\begin{equation}
	W_t = W_{t-1} - \alpha\nabla_WL(W)
	\label{grad_descent}
\end{equation}

\section{\textit{Stochastic Gradient Descent}}
Jika \textit{gradient descent} biasa melakukan pembaruan parameter untuk seluruh data, maka \textit{stochastic gradient descent} melakukan pembaruan parameter untuk setiap sampel data \cite{ruderOverviewGradientDescent2017}. Hal ini mengakibatkan pembaruan parameter pada metode \textit{stochastic gradient descent} terjadi lebih sering dan cepat. Pembaruan parameter menggunakan metode \textit{stochastic gradient descent} dilakukan berdasarkan persamaan (\ref{sgd}).
\begin{equation}
	W_t = W_{t-1} - \alpha\nabla_WL(W; x^{(i)}; y^{(i)})
	\label{sgd}
\end{equation}

\section{\textit{Adaptive Moment Estimation} (ADAM)}
Seperti namanya, ADAM (\textit{Adaptive Moment Estimation}) merupakan optimizer berbasis momentum \cite{sethiComprehensiveReviewOptimizers2019}. Konsep momentum memungkinkan ADAM untuk konvergen lebih cepat. Selain itu, ADAM juga memungkinkan pembaruan \textit{learning rate} model secara adaptif. ADAM memperbarui \textit{learning rate} secara adaptif untuk setiap parameter berdasarkan momen pertama ($m_t$) dan momen kedua ($v_t$) dari gradien \cite{sethiComprehensiveReviewOptimizers2019}. Optimasi ADAM bekerja dengan tahapan sebagai berikut:
\begin{enumerate}
	\item Definisikan \textit{learning rate} ($alpha$), laju peluruhan eksponensial untuk pendugaa momen ($\beta_1, \beta_2$), dan vektor parameter awal ($\theta_0$).
	\item Definisikan fungsi objektif dengan parameter $\theta$.
	\item Definisikan vektor momen pertama, yaitu $m_0 \leftarrow 0$ .
	\item Definisikan vektor omen kedua, yaitu $v_0 \leftarrow 0$.
	\item Definisikan $t \leftarrow 0$.
	\item Selama $\theta_t$ belum konvergen, ulangi langkah berikut:
	\begin{enumerate}
		\item $t \leftarrow t+1$
		\item $g_t = \nabla_\theta L_t(\theta_{t-1})$ (hitung gradien dari fungsi objektif).
		\item $m_t = \beta_1m_{t-1} + (1-\beta_1)g_t$ (perbarui estimasi momen pertama).
		\item $v_t = \beta_2v_{t-1} + (1-\beta_2)g_t^2$ (perbarui estimasi momen kedua).
		\item $\hat{m}_t = \frac{m_t}{1-\beta_1^t}$ (hitung estimasi momen pertama dengan bias yang sudah dikoreksi).
		\item $\hat{v}_t = \frac{v_t}{1-\beta_2^t}$ (hitung estimasi momen kedua dengan bias yang sudah dikoreksi).
		\item $\theta_t = \theta_{t-1} - \alpha \frac{\hat{m}_t}{\sqrt{\hat{v}_t}+\epsilon}$ (perbarui estimasi parameter $\theta$).
	\end{enumerate} 
	\item Diperoleh parameter $\theta$ terbaru.
\end{enumerate}

Misalkan \textit{loss function} yang diperoleh oleh sebuah model adalah $L(x) = (x-1)^2 $. Proses pembaruan parameter $x$ sehingga menghasilkan nilai \textit{loss function} yang minimal dilakukan dengan tahapan sebagai berikut:
\begin{enumerate}
	\item Tentukan \textit{learning rate} ($\alpha$), $\beta_1, \beta_2$, dan parameter awal $x_0$. misalkan dipilih $\alpha = 0,001$, $\beta_1 = 0,9$, $\beta_2=0,999$ dan $x_0 = 0$. 
	\item Definisikan fungsi objektif (\textit{loss function}) dengan parameter $x$, yaitu $L(x) = x^2 + 1$.
	\item Definisikan $m_0 = 0$.
	\item Definisikan $v_0 = 0$.
	\item Definisikan $t=0$.
	\item Selama $x_t$ belum konvergen, ulangi langkah berikut: 
	\begin{enumerate}
		\item $t=t+1$.
		\item Hitung gradien dari \textit{loss function}, yaitu $g_t = -2$.
		\item perbarui nilai $m_t$ 
		\begin{align}
			m_t &= \beta_1m_{t-1}+(1-\beta_1)g_t \\
			    &= 0 + (0,1)(-2) \\
			    &= -0,2
		\end{align}
		\item perbarui nilai $v_t$
		\begin{align}
			v_t &= \beta_2v_{t-1}+(1-\beta_2)g_t^2 \\
			&= 0 + (0,001)(4) \\
			&= 0,004
		\end{align}
		\item perbarui nilai $\hat{m}_t$
		\begin{align}
			\hat{m}_t &= \frac{m_t}{1-\beta_1^t} \\
			&= \frac{-0,2}{1-0,9} \\
			&= -2 
		\end{align}
		\item perbarui nilai $\hat{v}_t$
		\begin{align}
			\hat{v}_t &= \frac{v_t}{1-\beta_2^t} \\
			&= \frac{0,004}{1-0,999} \\
			&= 4
		\end{align}
		\item Perbarui parameter $x_t$. 
		\begin{align}
			x_t &= x_{t-1}-\alpha\frac{\hat{m}_t}{\sqrt{\hat{v}_t}+\epsilon} \\
			&= 0 - (0,001)\frac{-2}{2+10^{-8}} \\
			&= 0,001
		\end{align}
	\end{enumerate}
	\item Setelah pembaruan parameter untuk setiap nilai $t$ selesai dilakukan, maka nilai optimal parameter $x$ yang akan menghasilkan \textit{loss function} minimal akan diperoleh.
\end{enumerate}

\section{Metrik Evaluasi Model}
Terdapat beberapa metrik yang digunakan untuk mengevaluasi performa model \textit{deep learning}, beberapa di antaranya yang menjadi fokus pada penelitian ini yaitu \textit{accuracy}, \textit{precision}, dan \textit{recall}. Pada metrik evaluasi ini, terdapat beberapa istilah yang umum digunakan, yaitu: 
\begin{enumerate}
	\item \textit{True Positive} (TP). TP menunjukkan hasil positif yang diprediksi dengan benar oleh model
	\item \textit{True Negative} (TN). TN menunjukkan hasil negatif yang diprediksi dengan benar oleh model
	\item \textit{False Positive} (FP). FP menunjukkan hasil positif yang salah diprediksi oleh model
	\item \textit{False Negative} (FN). FN menunjukkan hasil negatif yang salah diprediksi oleh model
\end{enumerate}

Nilai TP, TN, FP, dan FN dapat divisualisasikan dalam bentuk matriks yang disebut sebagai \textit{confusion matrix} seperti pada Gambar \ref{conf_mat}.

\begin{figure}[H]
	\center \includegraphics[width=200px]{assets/confusion_matrix}
	\caption{Ilustrasi \textit{Confusion Mzzatrix}} 
	\label{conf_mat}
\end{figure}

Seperti yang telah disebutkan sebelumnya, terdapat beberapa metrik evaluasi penting pada model klasifikasi/deteksi, yaitu:
\begin{enumerate}
	\item \textit{Accuracy}. \textit{Accuracy} menyatakan proporsi sampel yang kelasnya diprediksi secara benar oleh model dari seluruh hasil prediksi. secara matematis dinyatakan oleh persamaan (\ref{accuracy}). Pada masalah deteksi intrusi, \textit{accuracy} menunjukkan seberapa banyak aktivitas intrusi yang berhasil dideteksi oleh model.
	\begin{equation}
		\begin{split}
			\text{accuracy} &= \frac{TP + TN}{TP + TN + FP + FN} 
		\end{split}
		\label{accuracy}
	\end{equation}
	\item \textit{Precision}. \textit{Precision} menyatakan proporsi kasus positif yang diprediksi oleh model dari semua kasus yang diprediksi positif oleh model. Pada masalah deteksi intrusi, \textit{precision} menyatakan persentase dari kasus intrusi yang diprediksi oleh model dari semua kasus yang diprediksi sebagai intrusi oleh model. Secara matematis, \textit{precision} dinyatakan oleh persamaan (\ref{precision}).
	\begin{equation}
		\begin{split}
			\text{precision} &= \frac{TP}{TP + FP} 
		\end{split}
		\label{precision}
	\end{equation}
	
	\item \textit{Recall (True Positive Rate)}. Secara matematis, \textit{recall} atau \textit{True Positive Rate} (TPR) dinyatakan oleh persamaan (\ref{recall}). \textit{Recall} menyatakan proporsi kasus positif aktual yang diprediksi dengan benar oleh model dari semua kasus positif aktual yang ada. Pada masalah deteksi intrusi, \textit{Recall} menunjukkan kemampuan model dalam mendeteksi semua kasus serangan yang sebenarnya ada pada dataset.
	\begin{equation}
		\begin{split}
			\text{recall atau TPR} &= \frac{TP}{TP + FN} 
		\end{split}
		\label{recall}
	\end{equation}
\end{enumerate}

%==============================================================
\chapter{METODE PENELITIAN}
Pada bab ini dijelaskan metode penelitian yang akan dilakukan, meliputi sumber data penelitian, dan tahap analisis yang akan dilakukan.

\section{Sumber Data}
Data yang digunakan untuk penelitian ini adalah dataset yang disediakan oleh \textit{Canadian Institute for Cybersecurity} pada situs https://www.unb.ca/cic/datasets/ids-2017.html (sampel data dapat dilihat pada Lampiran 1). Data ini merupakan \textit{generated data} oleh CIC yang didesain untuk meniru interaksi alami manusia dan menghasilkan data \textit{traffic} yang realistis. 

Dataset ini terdiri dari 79 kolom (deskripsi kolom pada Lampiran 2) dan 2.830.743 baris yang merepresentasikan \textit{flow}, yaitu aktivitas pengiriman serangkaian paket data (\textit{packets}) antara 2 titik (\textit{node}) di jaringan dalam satu sesi komunikasi. Setiap baris pada data memuat rincian informasi mengenai komunikasi antar \textit{node} pada jaringan komputer, seperti \textit{Flow Duration}, \textit{Packets Length}, dan sebagainya. Dari 79 kolom variabel, terdapat 1 kolom, yaitu 'label', yang akan diprediksi (variabel terikat) serta 77 kolom fitur (variabel bebas) penting yang akan digunakan pada analisis data. Sedangkan 1 kolom lainnya, yaitu 'Destination Port', tidak digunakan untuk analisis karena dianggap tidak memberikan kontribusi untuk proses deteksi intrusi.

\section{Metode Analisis}
Model yang digunakan untuk mengolah data dan dan melakukan tahapan deteksi intrusi adalah model \textit{Deep Neural Network} (DNN). Proses komputasi untuk penelitian ini dilakukan menggunakan \textit{software} Python dengan bantuan library \textit{TensorFlow} dengan \textit{Keras API}. Kode Program untuk penelitian ini tersediia pada Lampiran 3. Dari data yang diperoleh, model DNN akan dilatih untuk mengidentifikasi apakah suatu aktivitas pada jaringan merupakan aktivitas normal (BENIGN) atau serangan (ATTACK). 

\begin{figure}[H]
	\center \includegraphics[width=350px]{assets/diagram_penelitian}
	\caption{Diagram Alur Penelitian} 
	\label{diagram_penelitian}
\end{figure}

Gambar \ref{diagram_penelitian} menunjukkan tahapan analisis yang akan dilakukan dengan rincian sebagai berikut:
\begin{enumerate}
	\item Eksplorasi data mentah. Tahapan ini dilakukan untuk memberikan gambaran umum mengenai data. Pada kasus ini, informasi terpenting yang perlu diketahui tentang data adalah sebaran dari kelas serangan. Informasi ini akan memberikan gambaran umum bagaimana proporsi masing-masing kelas pada data. Informasi ini penting untuk memahami hasil prediksi yang diperoleh.
	
	\item \textit{Data preprocessing}. Tahapan \textit{data preprocessing} yang dilakukan meliputi pembagian data, \textit{data cleaning}, penskalaan data, dan transformasi data kategorik. Tahapan ini dilakukan untuk memperoleh data yang bebas dari kesalahan format serta skala data yang seragam.
	
	\item Konstruksi Model. Data hasil \textit{preprocessing} kemudian akan digunakan untuk melatih model DNN sehingga mampu mendeteksi intrusi jaringan. Model dilatih dengan \textit{hyperparameter} awal yang ditentukan.
	
	\item Evaluasi. Model yang diperoleh kemudian akan dievaluasi berdasarkan metrik evaluasi \textit{accuracy}, \textit{precision} dan \textit{recall}. Hasil evaluasi ini akan digunakan untuk mengatur \textit{hyperparameter} model sehingga memberikan hasil yang optimal.
	
	\item Interpretasi Hasil. Hasil evaluasi model dapat digunakan untuk memahami seberapa baik model kinerja model untuk deteksi intrusi ketika menghadapi skenario nyata.
\end{enumerate}

%==============================================================
\chapter{HASIL DAN PEMBAHASAN}
\section{Eksplorasi Data Mentah}
Pada tahap ini akan diamati proporsi masing-masing kelas pada data. Hal ini penting sebagai pertimbangan untuk evaluasi performa model. Terdapat 15 kelas serangan pada dataset. Karena penelitian ini ditujukan untuk deteksi intrusi, maka semua kelas serangan pada data dikonversi menjadi kelas "ATTACK". Visualisasi untuk distribusi kelas ini disajikan pada Gambar \ref{distribusi_kelas}:

\begin{figure}[H]
	\center \includegraphics[width=200px]{assets/pie-chart}
	\caption{Plot Distribusi Kelas} 
	\label{distribusi_kelas}
\end{figure}

Pada dataset ini juga terdapat beberapa \textit{missing values} yang harus ditangani sebelum model dikonstruksi. \textit{Missing values} pada dataset ini ditemukan di kolom "Flow Bytes/s" dan "Flow Packets/s" sebanyak 590 baris, atau sekitar $0,00033\%$ dari total data.

\section{Pra-pemrosesan Data}
\subsection{Pembagian Data}
Langkah pertama yang perlu dilakukan adalah pembagian data. Data dibagi menjadi data \textit{training}, \textit{validation}, dan \textit{testing}. Data \textit{training} digunakan untuk melatih model, data \textit{validation} digunakan untuk melihat performa model dan melakukan \textit{hyperparameter tuning}, dan data \textit{testing} digunakan untuk meninjau hasil akhir model yang diperoleh. Detail pembagian data disajikan pada Tabel \ref{pembagian_data}. 

\begin{table}[h!]
	\centering
	\caption{Proporsi Pembagian Data}
	\label{pembagian_data}
	\begin{tabular}{|c|c|c|c|}
		\hline
		& \textit{Training} & \textit{Validation} & \textit{Testing} \\
		\hline
		Jumlah & 1.243.706 & 266.509 & 266.509 \\
		\hline
		Persentase & 70\% & 15\% & 15\% \\
		\hline
		Proporsi Kelas BENIGN & 81\% & 81\% & 81\% \\
		\hline
		Proporsi Kelas ATTACK & 19\% & 19\% & 19\% \\
		\hline
	\end{tabular}
\end{table}

\subsection{Penanganan \textit{Missing Values}}
Seringkali data yang diperoleh, baik dari pengamatan langsung ataupun pihak eksternal, memiliki titik data yang rumpang. Nilai yang rumpang ini disebut sebagai \textit{missing value}. Terdapat berbagai macam metode untuk menangani \textit{missing value} pada data, seperti substitusi \textit{missing value} dengan median, mean, atau modus dari nilai pada kolom yang sama. Pada penelitian ini, \textit{missing values} akan disubstitusi dengan mean dari kolom yang bersesuaian. \\ 
\begin{table}
	\centering
	\caption{Sampel Data Aktivitas Jaringan}
	\label{sampel_data}
	\begin{longtable}{|r|r|r|r|r|}
		\hline
		No. & Flow & Total Fwd & Total Backward & Total Length of  \\
		 & Duration & Packets & Packets & Fwd Packets \\
		\hline
		0 & 640 & 7 & 4 & 440  \\
		\hline
		1 & 900 & 9 & 4 & 600  \\
		\hline
		2 & 1205 & 7 & 4 & 2776 \\
		\hline
		3 & 511 & 7 & 4 & 452 \\
		\hline
		\vdots & \vdots & \vdots & \vdots & \vdots \\
		\hline
		1243706 & 35396 & 9 & 4 & 612 \\
		\hline
	\end{longtable}
\end{table}

Berdasarkan Tabel \ref{sampel_data}, \textit{missing value} pada kolom \textit{Flow Duration} dapat disubstitusi dengan \textit{mean} dari kolom \textit{Flow Duration}, yaitu $\mu$.
\begin{equation}
	\mu = \frac{640 + 900 + 1205 + 511 + ...  + 35396}{1243706} = 20915909,1347
	\label{mean_flow}
\end{equation}

\subsection{Transformasi Data Kategorik}
Pada dataset, terdapat 1 variabel/fitur kategorik, yaitu 'Label' yang bernilai 'BENIGN' atau jenis serangan tertentu. Semua jenis serangan pada dataset ini kemudian diubah menjadi 1 jenis kelas, yaitu "ATTACK". Jadi, pada fitur "Label" terdapat 2 kemungkinan nilai, yaitu "BENIGN" dan "ATTACK", dimana kelas "BENIGN" kemudian ditransformasi menjadi 0, dan kelas "ATTACK" ditransformasi menjadi 1. Sehingga, pada saat pelatihan, model DNN hanya perlu menentukan apakah suatu aktivitas perlu dikategorikan sebagai 0 atau 1.

\subsection{Penskalaan Fitur}
Penskalaan fitur (\textit{feature scaling}) merupakan proses yang dilakukan untuk mentransformasi nilai numerik/kuantitatif ke dalam skala/interval tertentu, misalnya interval -1 sampai 1. Proses ini dilakukan untuk mempercepat proses konvergensi pada saat pelatihan model dan mencegah data dengan jangkauan yang besar mendominasi model. Terdapat beberapa teknik yang umum digunakan untuk transformasi ini, yaitu \textit{min-max scaling}, \textit{mean scaling}, dan \textit{z-score scaling} (\textit{standardization}) \cite{pajankarHandsonMachineLearning2022}. Pada penelitian ini, akan digunakan teknik \textit{standardization} untuk mentransformasi fitur numerik pada dataset sehingga memiliki rata-rata $\mu$ dan simpangan baku $\sigma$. Transformasi dengan standarisasi dilakukan dengan menggunakan persamaan (\ref{z-score}).
\begin{equation}
	Z = \frac{X-\mu}{\sigma}
	\label{z-score}
\end{equation}
Pada persamaan (\ref{z-score}), $X$ merupakan nilai awal yang ingin distandarisasi, dan $Z$ merupakan hasil standarisasi data. Dengan menggunakan \textit{z-score normalization}, fitur numerik \textit{Flow Duration} dapat dinormalisasi dengan menghitung mean dan ragam dari fitur tersebut.
\begin{equation}
	\begin{split}
		\mu &= 20915909.1347 \\
		\sigma &= \sqrt{\frac{(640-20915909,1347)^2 + ... + (900-20915909,1347)^2}{1243706}} \\
		&= 751794,22
	\end{split}
\end{equation}  
Dengan menggunakan informasi mean dan ragam dari nilai numerik pada kolom \textit{Flow Duration}, dapat dihitung \textit{z-score} sehingga menghasilkan Tabel \ref{tabelNorm}.

 \begin{longtable}{|l|l|l|}
	\caption{Hasil Normalisasi Fitur \textit{Flow Duration}} \label{tabelNorm}\\
	\hline
	No. & \textit{Flow Duration} & \textit{Standardized Flow Duration} \\ \hline
	0 & 640 & -0,53790744 \\ \hline
	1 & 900 & -0,53790744 \\ \hline
	2 & 1205 & -0,53790744 \\ \hline
	3 & 511	 & -0,53790743 \\ \hline
	\vdots & \vdots & \vdots \\ \hline
	4 & 35396 & -0,5379074 \\ \hline
\end{longtable}


\section{Konstruksi Model DNN} 
Setelah dilakukan \textit{preprocessing}, data akan digunakan untuk melatih model DNN agar mampu melakukan tugas deteksi intrusi. Berikut beberapa hal penting yang perlu diperhatikan terkait model dan \textit{optimizer} yang digunakan :

\begin{enumerate}
	\item Arstitektur Model. Model DNN pada penelitian ini terdiri dari 5 \textit{layer}. 1 input layer, 1 output layer, dan 3 \textit{hidden layer}. Masing-masing \textit{hidden layer} secara berturut-turut memiliki 32, 64, dan 32 \textit{node}. 
	
	\item \textit{Batch size}. Model \textit{deep learning} tidak dilatih pada keseluruhan data sekaligus, melainkan pada beberapa subset data secara bergantian untuk efisiensi sumber daya komputasi. Ukuran \textit{batch} atau \textit{batch size} menyatakan ukuran data input yang digunakan untuk melatih dan mengupdate parameter model. Pada penelitian ini, \textit{batch} yang digunakan pada pelatihan untuk setiap \textit{epoch} berukuran 128.
	
	\item Fungsi aktivasi. Karena model DNN pada penelitian ini dikembangkan untuk kebutuhan klasifikasi biner, maka fungsi aktivasi yang digunakan adalah fungsi sigmoid yang menghasilkan probabilitas prediksi.
	
	\item \textit{Optimizer}. Model dilatih menggunakan \textit{ADAM optimizer} dengan 70 \textit{epoch} dan \textit{learning rate} sebesar 0.0001. \textit{Epoch} menyatakan banyak iterasi yang dilakukan untuk melatih model. proses pelatihan secara berulang ini memungkinkan model dapat belajar dari data dengan lebih baik.
	
	\item \textit{Loss function}. \textit{Loss function} yang digunakan untuk mengevaluasi performa model ini adalah \textit{binary cross-entropy}. Fungsi ini dipilih karena model DNN ini dilatih untuk melakukan klasifikasi biner.
\end{enumerate}

Tabel \ref{tabel_arsitektur} menunjukkan arsitektur model DNN yang diimplementasikan pada penelitian ini. Tabel \ref{tabel_arsitektur} menunjukkan bahwa terdapat total parameter sebanyak $384,965$ dengan \textit{output shape} yang bervariasi pada tiap \textit{layer}. \textit{Output shape} pada masing-masing \textit{layer} merupakan sebuah \textit{tuple} yang terdiri dari 2 nilai. 2 nilai ini secara berturut-turut menunjukkan \textit{batch size} yang ditangani oleh layer tersebut dan jumlah \textit{node}-nya. Pada layer terakhir, terdapat 1 \textit{node} yang merepresentasikan probabilitas prediksi kelas. Nilai probabilitas yang sangat tinggi menunjukkan bahwa model memprediksi adanya intrusi.

\begin{longtable}{|l|  c|  r|}
	\caption{Tabel Arsitektur Model DNN}
	\label{tabel_arsitektur} \\
		\hline
		Layer (type) & Output Shape & Param \# \\
		\hline
		Dense & (None, 32) & 2496 \\
		\hline
		Dense & (None, 64) & 2112 \\
		\hline
		Dense & (None, 32) & 2080 \\
		\hline
		Dense & (None, 1) & 33 \\
		\hline
\end{longtable}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{assets/training_history}
	\caption{Plot Akurasi Klasifikasi pada Data \textit{Training} dan \textit{Validation}}
	\label{training_history}
\end{figure}

Gambar \ref{training_history} menunjukkan tingkat akurasi yang dicapai oleh model DNN pselama proses pelatihan. Dapat diamati bahwa tren akurasi model menunjukkan bahwa model mendapatkan peningkatan akurasi yang signifikan selama beberapa \textit{epoch} awal dan mulai konvergen dengan sedikit fluktuasi. Grafik ini menunjukkan mengindikasikan bahwa model mempelajari data \textit{training} dengan baik dan bahkan melakukan \textit{klasifikasi} pada data \textit{validation} dengan akurasi yang sangat tinggi. 

\subsection{Mekanisme Model}
Untuk menjelaskan mekanisme model, data akan disampel dengan 5 fitur saja. Model DNN untuk deteksi intrusi bekerja dengan mekanisme sebagai berikut:

Misalkan inisiasi bobot awal model sebagai berikut :
\begin{equation}
	\begin{split}
		\mathbf{W}_{1} =\mathbf{W}_{2} = \mathbf{W}_{3} = \mathbf{W}_{4} = \begin{bmatrix}
			0,1 & 0,1 & \dots & 0,1 \\
			\vdots & \vdots & \ddots & \vdots \\
			0,1 & 0,1 & \dots & 0,1 \\
		\end{bmatrix} &\in \mathbb{R}^{128 \times 6}, \\
		X &\in \mathbb{R}^{6} \\
	\end{split}
\end{equation}

\begin{itemize}
	\item Untuk \textit{epoch} ke-1
	\begin{itemize}
		\item Untuk \textit{batch} ke-1
		\begin{itemize}
			\item Untuk data pertama pada \textit{batch}-1 ($X_1$)
			\begin{enumerate}
				\item Untuk \textit{layer} pertama
				\begin{equation}
					\begin{split}
						X_1 &= \begin{bmatrix}
							-0,53289452 \\
							-0,01148982 \\
							-0,01007426 \\
							-0,04567971 \\
							-0,00826494 \\
							1 \\
						\end{bmatrix} \\
					\end{split}
				\end{equation}
				\begin{equation}
					\begin{split}
						A_1 &= \textit{ReLU}(\mathbf{W}_1X_1) \\
						&= ReLU \left(
						\begin{bmatrix}
							0,1 & 0,1 & \dots & 0,1 \\
							\vdots & \vdots & \ddots & \vdots \\
							0,1 & 0,1 & \dots & 0,1 \\
						\end{bmatrix} \begin{bmatrix}
							-0,53289452 \\
							-0,01148982 \\
							-0,01007426 \\
							-0,04567971 \\
							-0,00826494 \\
							1 \\
						\end{bmatrix}
						\right) \\ 
						&= ReLU \left(\begin{bmatrix} 0,03915968 &  0,03915968 & 0,03915968 & ... &  0,03915968 \end{bmatrix}^{T} \right) \notag\\ 
						&= \begin{bmatrix} 0,03915968 &  0,03915968 & 0,03915968 & ... &  0,03915968 \end{bmatrix}^{T}
					\end{split}
				\end{equation}
				Vektor $A_1$ akan diteruskan sebagai input untuk \textit{layer} ke-2
				
				\item Nilai aktivasi pada setiap \textit{neuron} di \textit{layer} ke-2 ($A_2$) akan dhitung dengan cara yang sama dengan perhitungan $A_1$. Begitu juga untuk \textit{layer} ke-3 dan ke-4 dengan mempertimbangkan fungsi aktivasi pada setiap \textit{layer}
				
			\end{enumerate} 
				
			\item Proses komputasi yang sama dilakukan pada data berikutnya sampai data terakhir pada \textit{batch} tersebut. Kemudian, akan dihitung \textit{loss function} yang diperoleh. \textit{Loss function} ini akan digunakan untuk mengoptimalkan nilai parameter $\mathbf{W}_{1}, \mathbf{W}_{2}, \mathbf{W}_{3}$ dan $\mathbf{W}_{4}$.
		\end{itemize}
		\item Proses komputasi yang sama dilakukan hingga \textit{batch} terakhir.
	\end{itemize}
	\item proses yang sama dilakukan pada setiap \textit{epoch}.
\end{itemize}

Mekanisme komputasi ini diimplementasikan menggunakan bahasa pemrograman \textit{Python} dengan bantuan \textit{framework Tensorflow} dan API \textit{Keras}. Model dikembangkan menggunakan arsitektur yang ditunjukkan oleh tabel \ref{tabel_arsitektur} dan dilatih sebanyak $70$ \textit{epoch} menggunakan \textit{ADAM optimizer}.

\section{Hasil dan Evaluasi}
Setelah melewati pelatihan sebanyak $70$ epoch, model memiliki tingkat akurasi yang mendekati $100\%$ pada data \textit{validation}. \textit{Confusion matrix} pada Tabel \ref{conf_mat_hasil} menunjukkan perbandingan hasil prediksi model dengan kelas yang sebenarnya. Berdasarkan Tabel \ref{conf_mat_hasil} terlihat bahwa model mampu memprediksi hampir semua \textit{flow} normal (BENIGN) dan serangan \textit{ATTACK} dengan benar pada data \textit{testing}. 

\begin{table}[!h]
	\centering
	\caption{\textit{Confusion matrix} hasil prediksi model pada data \textit{testing}}
	\label{conf_mat_hasil}
	\begin{tabular}{|c|c|c|c|}
		\hline
		\multicolumn{2}{|c|}{} & \multicolumn{2}{|c|}{Nilai Sebenarnya} \\
		\cline{3-4}
		\multicolumn{2}{|c|}{} & ATTACK (1) & BENIGN (0) \\
		\hline
		Nilai & ATTACK (1) & 49654 & 328 \\
		\cline{2-4}
		Prediksi & BENIGN (0) & 822 & 215705 \\
		\hline
	\end{tabular}
\end{table}

Tabel \ref{classification_report} menunjukkan beberapa metrik evaluasi penting pada data \textit{testing} untuk masalah klasifikasi terhadap model yang telah dikembangkan. Berdasarkan Tabel \ref{classification_report}, terlihat bahwa metrik \textit{precision} bernilai  $99\%$ pada kelas ATTACK dan mendekati $100\%$ pada kelas BENIGN.  Nilai \textit{precision} yang tinggi menunjukkan bahwa ketika model memprediksi adanya serangan, kemungkinan besar hal itu benar. Hal ini merupakan indikasi yang bagus untuk sebuah model deteksi, karena metrik ini menunjukkan bahwa model dapat diandalkan untuk mendeteksi intrusi. 
\begin{table}[h!]
	\centering
	\caption{Classification Report untuk Data \textit{Testing}}
	\label{classification_report}
	\begin{tabular}{|l|r|r|r|}
		\hline
		% Header Row
		& \textbf{precision} & \textbf{recall} & \textbf{support} \\
		\hline
		% Data Rows (spasi sudah dibersihkan)
		ATTACK & 0,993 & 0,984 & 50476 \\
		\hline
		BENIGN & 0,996 & 0,998 & 216033 \\
		\hline
		% Baris Akurasi (format sudah diperbaiki)
		\multicolumn{4}{|c|}{Accuracy \hfill 0,996} \\
		\hline
		\multicolumn{4}{|c|}{Balanced Accuracy \hfill 0.991} \\
		\hline
	\end{tabular}
\end{table}

Kolom \textit{recall} pada Tabel \ref{classification_report} menunjukkan proporsi \textit{True Positive} (TP) terhadap semua \textit{flow} pada kelas yang terkait. Nilai ini juga menunjukkan bahwa emakin tinggi \textit{recall} yang diperoleh, maka semakin kecil pula nilai \textit{False Negative} (FN) yang didapatkan.  Berdasarkan tabel \ref{classification_report}, terlihat bahwa model yang telah dikonstruksi memiliki \textit{recall} yang tinggi pada kedua kelas, baik kelas BENIGN ataupun kelas ATTACK. Hal ini mengindikasikan bahwa model mampu memprediksi hampir semua kelas dari \textit{flow} yang ada dengan benar walaupun dengan proporsi kelas yang tidak seimbang, seperti yang ditunjukkan oleh kolom \textit{support} pada Tabel \ref{classification_report}. 

Pada model yang dikembangkan untuk tujuan deteksi, nilai \textit{recall} yang tinggi ini merupakan poin penting untuk diperhatikan karena gagal mendeteksi intrusi (FN yang tinggi) justru lebih berbahaya daripada kegagalan memprediksi aktivitas biasa sebagai aktivitas serangan (FP yang tinggi). Pada Tabel \ref{classification_report} dapat dilihat bahwa berdasarkan nilai \textit{recall} yang diperoleh, model sudah bekerja dengan performa yang cukup tinggi untuk mendeteksi intrusi, bahkan pada jenis serangan yang belum pernah dilihat sebelumnya.


%==============================================================
\chapter{KESIMPULAN DAN SARAN}

\section{Kesimpulan}
Berdasarkan hasil hasil yang diperoleh dari penelitian, dapat ditarik beberapa kesimpulan sebagai berikut :
\begin{enumerate}
	\item Model yang dikonstruksi, yaitu model \textit{deep neural network} (DNN) dengan arsitektur 3 \textit{hidden layer} dengan jumlah \textit{nuron} berturut-turut 32, 64, dan 32 memperoleh \textit{accuracy} dan \textit{balanced accuracy} yang konvergen ke nilai yang cukup tinggi, mencapai $99\%$ pada data \textit{testing}. Model ini menggunakan fungsi aktivasi ReLU pada \textit{hidden layer} dan fungsi aktivasi \textit{sigmoid} pada \textit{output layer}. Model dilatih dengan ukuran \textit{batch} 128, 70 \textit{epoch} dan \textit{learning rate} 0.0001 menggunakan \textit{ADAM optimizer}.
	 
	\item Berdasarkan \textit{classification report} pada tabel \ref{classification_report}, model menunjukkan performa yang cukup tinggi tidak hanya pada metrik \textit{accuracy}, tetapi juga pada metrik \textit{precision} dan \textit{recall} pada pada kedua kelas dengan nilai lebih dari $90\%$. Artinya, model mampu mendeteksi hampir semua kejadian serangan yang mungkin muncul. Hal ini merupakan indikasi yang baik pada model untuk kasus deteksi intrusi.
\end{enumerate}
\section{Saran}
Saran Penulis untuk penelitian berikutnya yaitu :
\begin{enumerate}
	\item Melatih model DNN pada dataset dengan jenis serangan yang lebih beragam untuk mengevaluasi seberapa baik generalisasi model pada data dengan jenis serangan yang lebih beragam
	
	\item Melakukan reduksi/ekstraksi fitur supaya proses pelatihan model berjalan dengan lebih efisien.
\end{enumerate}

%%=======================================================

\newpage
\addcontentsline{toc}{chapter}{DAFTAR PUSTAKA}
\bibliographystyle{IEEEtran}
\bibliography{dapus}

\newpage
\addcontentsline{toc}{chapter}{LAMPIRAN}
\chapter*{LAMPIRAN}
	\newappendix{\normalsize Lampiran 1 \textnormal{Dataset Intrusi}}
	\begin{table}[h!]
		\centering
		\scriptsize
		\begin{tabular}{|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
			\hline
			No & Flow Duration & Total Fwd Packets & Total Backward Packets & Total Length of Fwd Packets & ... & Label \\
			\hline
			1 & 24144361 & 5 & 0 & 24144361 & ... & ATTACK \\
			\hline
			2 & 11666 & 3 & 6 & 11666 & ... & ATTACK \\
			\hline
			3 & 701282 & 3 & 4 & 701282 & ... & ATTACK \\
			\hline
			4 & 60351 & 1 & 1 & 60351 & ... & BENIGN \\
			\hline
			5 & 99094549 & 9 & 5 & 99094549 & ... & ATTACK \\
			\hline
			6 & 1394971 & 3 & 6 & 1394971 & ... & ATTACK \\
			\hline
			7 & 60586247 & 17 & 14 & 60586247 & ... & BENIGN \\
			\hline
			8 & 191 & 2 & 2 & 191 & ... & BENIGN \\
			\hline
			9 & 84 & 1 & 1 & 84 & ... & BENIGN \\
			\hline
			10 & 8669606 & 9 & 15 & 8669606 & ... & ATTACK \\
			\hline
			11 & 113827448 & 21 & 18 & 113827448 & ... & BENIGN \\
			\hline
			12 & 93861502 & 2 & 0 & 93861502 & ... & ATTACK \\
			\hline
			13 & 882496 & 3 & 4 & 882496 & ... & ATTACK \\
			\hline
			14 & 112063014 & 66 & 37 & 112063014 & ... & BENIGN \\
			\hline
			15 & 157 & 2 & 0 & 157 & ... & BENIGN \\
			\hline
			16 & 68643576 & 5 & 7 & 68643576 & ... & ATTACK \\
			\hline
			17 & 1184154 & 3 & 5 & 1184154 & ... & ATTACK \\
			\hline
			18 & 31283 & 4 & 2 & 31283 & ... & BENIGN \\
			\hline
			19 & 70889266 & 8 & 6 & 70889266 & ... & ATTACK \\
			\hline
			20 & 61320 & 2 & 2 & 61320 & ... & BENIGN \\
			\hline
			21 & 77045 & 3 & 5 & 77045 & ... & ATTACK \\
			\hline
			22 & 526697 & 3 & 6 & 526697 & ... & ATTACK \\
			\hline
			23 & 5465558 & 3 & 1 & 5465558 & ... & ATTACK \\
			\hline
			24 & 48576 & 2 & 2 & 48576 & ... & BENIGN \\
			\hline
			25 & 50215 & 2 & 2 & 50215 & ... & BENIGN \\
			\hline
			26 & 99959892 & 8 & 6 & 99959892 & ... & ATTACK \\
			\hline
			27 & 64036939 & 2 & 2 & 64036939 & ... & BENIGN \\
			\hline
			28 & 146134 & 36 & 50 & 146134 & ... & BENIGN \\
			\hline
			29 & 63149593 & 7 & 0 & 63149593 & ... & ATTACK \\
			\hline
			30 & 61093329 & 17 & 15 & 61093329 & ... & BENIGN \\
			\hline
			31 & 91092568 & 20 & 21 & 91092568 & ... & BENIGN \\
			\hline
			32 & 401776 & 6 & 0 & 401776 & ... & BENIGN \\
			\hline
			33 & 84555234 & 5 & 7 & 84555234 & ... & ATTACK \\
			\hline
			34 & 5325576 & 13 & 11 & 5325576 & ... & BENIGN \\
			\hline
			35 & 101732985 & 8 & 5 & 101732985 & ... & ATTACK \\
			\hline
			36 & 5208946 & 3 & 1 & 5208946 & ... & BENIGN \\
			\hline
			37 & 98358738 & 7 & 5 & 98358738 & ... & ATTACK \\
			\hline
			38 & 81827 & 3 & 7 & 81827 & ... & ATTACK \\
			\hline
			39 & 1746 & 2 & 2 & 1746 & ... & BENIGN \\
			\hline
			40 & 5382316 & 9 & 6 & 5382316 & ... & BENIGN \\
			\hline
			\vdots & \vdots & \vdots & \vdots & \vdots & ... & \vdots \\
			\hline
			2830743 & 4 & 2 & 0 & 4 & ... & BENIGN \\
			\hline
		\end{tabular}
		
	\end{table}
	\noindent Dataset lengkap tersedia di halaman https://www.unb.ca/cic/datasets/ids-2017.html.

\newpage
	\newappendix{\normalsize Lampiran 2 \textnormal{Keterangan fitur/variabel}}
\begin{table}[h!]
	\centering
	\begin{longtable}{|p{3cm}| p{10cm}|}
		\hline
		Variabel/Fitur & Keterangan \\
		\hline
		Flow Duration & Durasi total aliran (flow) dalam mikrodetik. \\
		\hline
		Total Fwd Packets & Jumlah total paket yang dikirim di arah maju (dari sumber ke tujuan). \\
		\hline
		Total Backward Packets & Jumlah total paket yang dikirim di arah mundur (dari tujuan kembali ke sumber). \\
		\hline
		Total Length of Fwd Packets & Total panjang (dalam byte) semua paket di arah maju. \\
		\hline
		Total Length of Bwd Packets & Total panjang (dalam byte) semua paket di arah mundur. \\
		\hline
		Fwd Packet Length Max & Panjang maksimum paket di arah maju. \\
		\hline
		Fwd Packet Length Min & Panjang minimum paket di arah maju. \\
		\hline
		Fwd Packet Length Mean & Rata-rata panjang paket di arah maju. \\
		\hline
		Fwd Packet Length Std & Standar deviasi panjang paket di arah maju. \\
		
		Bwd Packet Length Max & Panjang maksimum paket di arah mundur. \\
		\hline
		Bwd Packet Length Min & Panjang minimum paket di arah mundur. \\
		\hline
		Bwd Packet Length Mean & Rata-rata panjang paket di arah mundur. \\
		\hline
		Bwd Packet Length Std & Standar deviasi panjang paket di arah mundur. \\
		\hline
		Flow Bytes/s & Jumlah byte per detik dalam aliran. \\
		\hline
		Flow Packets/s & Jumlah paket per detik dalam aliran. \\
		\hline
		Flow IAT Mean & Rata-rata waktu antar kedatangan (Inter-Arrival Time) untuk semua paket dalam aliran. \\
		\hline
		Flow IAT Std & Standar deviasi waktu antar kedatangan untuk semua paket dalam aliran. \\
		\hline
		Flow IAT Max & Waktu antar kedatangan maksimum dalam aliran. \\
		\hline
		Flow IAT Min & Waktu antar kedatangan minimum dalam aliran. \\
		\hline
		Fwd IAT Total & Total waktu antar kedatangan untuk semua paket di arah maju. \\
		\hline
		Fwd IAT Mean & Rata-rata waktu antar kedatangan untuk paket di arah maju. \\
		\hline
	\end{longtable}
\end{table}
\newpage

\begin{table}[h!]
	\centering
	\begin{longtable}{|p{3cm} |p{10cm}|}
		\hline
		Fwd IAT Std & Standar deviasi waktu antar kedatangan paket di arah maju. \\
		\hline
		Fwd IAT Max & Waktu antar kedatangan maksimum paket di arah maju. \\
		\hline
		Fwd IAT Min & Waktu antar kedatangan minimum paket di arah maju. \\
		\hline
		Bwd IAT Total & Total waktu antar kedatangan paket di arah mundur. \\
		\hline
		Bwd IAT Mean & Rata-rata waktu antar kedatangan paket di arah mundur. \\
		\hline
		Bwd IAT Std & Standar deviasi waktu antar kedatangan paket di arah mundur. \\
		\hline
		Bwd IAT Max & Waktu antar kedatangan maksimum paket di arah mundur. \\
		\hline
		Bwd IAT Min & Waktu antar kedatangan minimum paket di arah mundur. \\
		\hline
		Fwd PSH Flags & Jumlah flag PSH aktif di arah maju. \\
		\hline
		Bwd PSH Flags & Jumlah flag PSH aktif di arah mundur. \\
		\hline
		Fwd URG Flags & Jumlah flag URG aktif di arah maju. \\
		\hline
		Bwd URG Flags & Jumlah flag URG aktif di arah mundur. \\
		\hline
		Fwd Header Length & Total ukuran header dalam byte di arah forward. \\
		\hline
		Bwd Header Length & Total ukuran header dalam byte di arah backward. \\
		\hline
		Fwd Packets/s & Jumlah paket forward yang ditransfer per detik. \\
		\hline
		Bwd Packets/s & Jumlah paket backward yang ditransfer per detik. \\
		\hline
		Min Packet Length & Ukuran paket minimum dalam keseluruhan aliran. \\
		\hline
		Max Packet Length & Ukuran paket maksimum dalam keseluruhan aliran. \\
		\hline
		Packet Length Mean & Ukuran rata-rata paket dalam keseluruhan aliran. \\
		\hline
		Packet Length Std & Standar deviasi ukuran paket dalam keseluruhan aliran. \\
		\hline
		Packet Length Variance & Varian dari ukuran paket dalam keseluruhan aliran. \\
		\hline
		FIN Flag Count & Jumlah total flag FIN dalam aliran. \\
		\hline
		SYN Flag Count & Jumlah total flag SYN dalam aliran. \\
		\hline
		RST Flag Count & Jumlah total flag RST dalam aliran. \\
		\hline
		PSH Flag Count & Jumlah total flag PSH dalam aliran. \\
		\hline
		ACK Flag Count & Jumlah total flag ACK dalam aliran. \\
		\hline
		URG Flag Count & Jumlah total flag URG dalam aliran. \\
		\hline
		CWE Flag Count & Jumlah total flag CWE (Congestion Window Reduced) dalam aliran. \\
		\hline
	\end{longtable}
\end{table}
\newpage

\begin{table}[h!]
	\centering
	\begin{longtable}{|p{3cm} | p{10cm} |}
		\hline
		ECE Flag Count & Jumlah total flag ECE (ECN-Echo) dalam aliran. \\
		\hline
		Down/Up Ratio & Rasio jumlah paket backward terhadap paket forward. \\
		\hline
		Average Packet Size & Ukuran rata-rata paket (termasuk forward dan backward). \\
		\hline
		Avg Fwd Segment Size & Ukuran rata-rata segmen di arah forward (sama dengan `Fwd Packet Length Mean`). \\
		\hline
		Avg Bwd Segment Size & Ukuran rata-rata segmen di arah backward (sama dengan `Bwd Packet Length Mean`). \\
		\hline
		Fwd Header Length.1 & Fitur duplikat dari `Fwd Header Length`. \\
		\hline
		Fwd Avg Bytes/Bulk & Rata-rata byte per bulk di arah forward (seringkali 0). \\
		\hline
		Fwd Avg Packets/Bulk & Rata-rata paket per bulk di arah forward (seringkali 0). \\
		\hline
		Fwd Avg Bulk Rate & Rata-rata laju bulk di arah forward (seringkali 0). \\
		\hline
		Bwd Avg Bytes/Bulk & Rata-rata byte per bulk di arah backward (seringkali 0). \\
		\hline
		Bwd Avg Packets/Bulk & Rata-rata paket per bulk di arah backward (seringkali 0). \\
		\hline
		Bwd Avg Bulk Rate & Rata-rata laju bulk di arah backward (seringkali 0). \\
		\hline
		Subflow Fwd Packets & Rata-rata jumlah paket dalam sub-aliran forward. \\
		\hline
		Subflow Fwd Bytes & Rata-rata jumlah byte dalam sub-aliran forward. \\
		\hline
		Subflow Bwd Packets & Rata-rata jumlah paket dalam sub-aliran backward. \\
		\hline
		Subflow Bwd Bytes & Rata-rata jumlah byte dalam sub-aliran backward. \\
		\hline
		Init Win bytes forward & Total byte yang dikirim pada jendela TCP awal di arah forward. \\
		\hline
		Init Win bytes backward & Total byte yang dikirim pada jendela TCP awal di arah backward. \\
		\hline
		act data pkt fwd & Jumlah paket forward yang memiliki payload. \\
		\hline
		min seg size forward & Ukuran minimum header yang diamati di arah forward (biasanya 20 untuk TCP). \\
		\hline
		Active Mean & Waktu rata-rata aliran aktif sebelum menjadi idle. \\
		\hline
		Active Std & Standar deviasi waktu aktif aliran. \\
		\hline
		Active Max & Waktu aktif maksimum aliran. \\
		\hline
		Active Min & Waktu aktif minimum aliran. \\
		\hline
		Idle Mean & Waktu idle (jeda) rata-rata dalam aliran. \\
		\hline
		Idle Std & Standar deviasi waktu idle dalam aliran. \\
		\hline
		Idle Max & Waktu idle maksimum dalam aliran. \\
		\hline
		Idle Min & Waktu idle minimum dalam aliran. \\
		\hline
	\end{longtable}
\end{table}

\newpage
\newappendix{\normalsize Lampiran 3 \textnormal{Kode Program Python}}
\begin{lstlisting}
dataset_path = kagglehub.dataset_download('chethuhn/network-
intrusion-dataset')

print('Data source import complete. \n')
print("Information about your data sources:")
print(f"Dataset path: {dataset_path}")

"""## Import Library"""

# Import library yang diperlukan
import pandas as pd
import numpy as np
import os
from sklearn.model_selection import train_test_split, 
TimeSeriesSplit
from sklearn.preprocessing import StandardScaler, LabelEncoder, 
MinMaxScaler
from sklearn.impute import SimpleImputer
import tensorflow as tf
from tensorflow.keras import layers, Model
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

"""## Preprocessing Data

### Load Data
"""

# Fungsi untuk membaca dan preprocessing setiap file
def read_and_clean_file(file_path):
print(f"Membaca file: {file_path}")
df = pd.read_csv(file_path, low_memory=False, sep=",")

# Bersihkan nama kolom dari whitespace
df.columns = df.columns.str.strip()

# Hapus kolom yang tidak diperlukan
redundant_column = ['Destination Port']
df = df.drop(redundant_column, axis=1)

# drop baris yang tidak punya label
df.dropna(subset = ['Label'], inplace=True)

# Handling missing values dan infinite values
df = df.replace([np.inf, -np.inf], np.nan)

return df


# Baca semua file CSV dari folder
data1 = dataset_path + "/Monday-WorkingHours.pcap_ISCX.csv"
data2 = dataset_path + "/Tuesday-WorkingHours.pcap_ISCX.csv"
data3 = dataset_path + "/Wednesday-workingHours.pcap_ISCX.csv"
data4 = dataset_path + "/Thursday-WorkingHours-Morning-WebAttacks
.pcap_ISCX.csv"
data5 = dataset_path + "/Thursday-WorkingHours-Afternoon
-Infilteration.pcap_ISCX.csv"
data6 = dataset_path + "/Friday-WorkingHours-Morning.pcap_ISCX.csv"
data7 = dataset_path + "/Friday-WorkingHours-Afternoon-PortScan.
pcap_ISCX.csv"
data8 = dataset_path + "/Friday-WorkingHours-Afternoon-DDos.pcap_
ISCX.csv"


# Buat list semua dataset yang tersedia
all_files = [data2, data3, data4, data5, data6, data7, data8]


dataframes = []
for file in all_files:
df = read_and_clean_file(file)
dataframes.append(df)
del df

# Menggabungkan semua dataframe
print("Menggabungkan semua file...")
df = pd.concat(dataframes, ignore_index=True)
try:
print("Semua file dataset berhasil digabungkan!")
except:
print("Error! file dataset tidak berhasil digabungkan")

"""### Pembersihan Data Duplikat"""

# ganti nama kolom dengan cara hapus whitespaces
col_names = {col: col.strip() for col in df.columns}
df.rename(columns = col_names, inplace = True)

# informasi data duplikat
dups = df[df.duplicated()]
print(f'Banyak data duplikat : {len(dups)}')
print(f'Banyak data sebelum duplikat : {df.shape[0]}')

print("menghapus data duplikat...")

# Hapus data duplikat
df.drop_duplicates(inplace = True)
print("data duplikat selesai dihapus!")
df.shape
print(f"banyak data setelah data duplikat dihapus : {df.shape[0]}")

"""### Persiapan Label Kelas untuk Klasifikasi Biner"""

# konversi semua label selain BENIGN jadi ATTACK
df["Label"] = df["Label"].where(df["Label"] == "BENIGN", "ATTACK")
print("Informasi Kelas : ")
df["Label"].unique()

att = df[df['Label'] == 'ATTACK']
att[kolom]

head = df.head(60)

kolom = ['Flow Duration', 'Total Fwd Packets', 'Total Backward 
Packets', 'Total Length of Fwd Packets', 'Label']

head = head[kolom]
print(f"No & {kolom[0]} & {kolom[1]} & {kolom[2]} & {kolom[3]} & ... 
& {kolom[4]} \\\\")
for i in range(60):
baris = head.iloc[i]
print(f"{i+1} & {baris[kolom[0]]} & {baris[kolom[1]]} & 
{baris[kolom[2]]} & {baris[kolom[0]]} & ... & {baris['Label']} \\\\")
print("\\hline")

"""## Informasi Umum Dataset"""

# Menampilkan informasi dataset
print("\nInformasi Dataset:")
print(f"\nJumlah total data: {len(df)}")
print(f"Jumlah fitur : {len(df.columns)}")
print("\nDistribusi Label sebelum preprocessing:")

# tabel distribusi label
def create_distribution_table(df):
label_dist = pd.DataFrame(df['Label'].value_counts())
label_dist['percentage'] = df['Label'].value_counts()/len(df)
return label_dist

create_distribution_table(df)

"""## Pemisahan Data Fitur (X) dan Output (y)"""

numerical_columns = df.select_dtypes(include=[np.number]).columns
X = df[numerical_columns]
y = df["Label"]
print(f"jumlah fitur : {len(X.columns)}")
print(f"jumlah label : {len(y.unique())}")

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp,
 test_size=0.5, random_state=42, stratify=y_temp)

print(f"Ukuran data training (X_train, y_train): {X_train.shape}, 
{y_train.shape}")
print(f"Ukuran data validation (X_val, y_val): 
{X_val.shape}, {y_val.shape}")
print(f"Ukuran data testing (X_test, y_test): {X_test.shape},
 {y_test.shape}")


print("\nDistribusi Label pada Training Set:")
print(y_train.value_counts(normalize=True))

print("\nDistribusi Label pada Validation Set:")
print(y_val.value_counts(normalize=True))

print("\nDistribusi Label pada Testing Set:")
print(y_test.value_counts(normalize=True))


import pandas as pd
pd.set_option('display.max_columns', None)


# Periksa baris dengan missing values dalam DataFrame
print("\nBaris dengan missing values:")
df[df.isnull().any(axis=1)]

# Hitung jumlah NaN per kolom
nan_counts = df.isnull().sum()

# Cetak jumlah baris dengan nilai NaN per kolom
print("\nJumlah baris dengan nilai NaN per kolom:")
nan_counts[nan_counts > 0]

590/len(df)

"""## Transformasi Data"""

# imputer
imputer = SimpleImputer(missing_values=np.nan, strategy='mean', 
copy=False)
print("fitting imputer...")
imputer.fit(X_train)
print("selesai!")

# scaler
scaler = StandardScaler(copy=False)
print("\nfitting scaler...")
scaler.fit(X_train)
print("selesai!")

# label encoder (le)
le = LabelEncoder()
print("\nfitting label encoder...")
le.fit(y_train.astype(str))
print("selesai!")

for i, label in enumerate(le.classes_):
print(f"i : {i} , label : {label}")

# Menampilkan informasi kelas
print("\nKelas yang terdeteksi:")
for i, label in enumerate(le.classes_):
count = (df["Label"] == le.classes_[i]).sum()
print(f"{label}: {count} samples (encoded as {i})")

def transform_data(X, y, scaler, imputer, le):
# Handling missing values untuk dataset training
print("\nMenangani missing values...")
X = imputer.transform(X)
print("selesai!")

# Normalisasi Data
print("\nMelakukan normalisasi data...")
X = scaler.transform(X)
print("selesai!")

# Pelabelan Kelas
num_classes = len(le.classes_)
print("\nMelakukan one-hot encoding...")
y = le.transform(y)
print("selesai!")

return X, y

## Transformasi Data Training
X_train, y_train = transform_data(X_train, y_train, scaler, imputer,
 le)

## Transformasi Data Validation
X_val, y_val = transform_data(X_val, y_val, scaler, imputer, le)

# Transformmasi data testing
X_test, y_test = transform_data(X_test, y_test, scaler, imputer, le)

"""## Konstruksi Model DNN"""


# Membangun model DNN
input_shape = (X_train.shape[1],)

model = tf.keras.Sequential([
layers.InputLayer(input_shape=input_shape),
layers.Dense(32, activation='relu'),
layers.Dense(64, activation='relu'), 
layers.Dense(32, activation='relu'), 
layers.Dense(1, activation='sigmoid') 
])

# Compile Model
optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)
model.compile(optimizer=optimizer,
loss='binary_crossentropy',
metrics=['accuracy', 'precision', 'recall'])

history = model.fit(X_train, y_train,
epochs=70,
batch_size=128,
validation_data=(X_val, y_val)
)

# Menampilkan ringkasan model
model.summary()

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('DNN Training History')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.savefig("training_history")

# Evaluasi model
y_pred_prob = model.predict(X_test)
y_pred_classes = (y_pred_prob > 0.5).astype(int)
y_test_classes = y_test

# Tampilkan hasil evaluasi
print("\nClassification Report:")
print(classification_report(y_test_classes, y_pred_classes, 
target_names=le.classes_))

import matplotlib.pyplot as plt
# Confusion Matrix
cm = confusion_matrix(y_test_classes, y_pred_classes)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.
classes_, yticklabels=le.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

from sklearn.metrics import balanced_accuracy_score

balanced_acc = balanced_accuracy_score(y_test_classes, y_pred_classes)
print(f"Balanced Accuracy: {balanced_acc}")

# Simpan model
print("\nMenyimpan model...")
model.save('model.keras')

import pickle

# Simpan history ke file
with open('history.pkl', 'wb') as file_pi:
pickle.dump(history.history, file_pi)

# Simpan label encoder
import joblib
joblib.dump(le, 'label_encoder.joblib')
joblib.dump(scaler, 'scaler.joblib')
joblib.dump(imputer, 'imputer.joblib')


\end{lstlisting}


\end{document}
%=============================================================
